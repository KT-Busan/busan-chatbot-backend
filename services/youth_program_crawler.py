import requests
import re
import time
import json
import os
from bs4 import BeautifulSoup
from urllib.parse import urljoin
from datetime import datetime, timedelta


class BusanYouthProgramCrawler:
    def __init__(self):
        self.base_url = "https://young.busan.go.kr"
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'ko-KR,ko;q=0.8,en-US;q=0.5,en;q=0.3',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
        })
        self.programs_data = []

    def get_page_content(self, url, encoding='utf-8'):
        """í˜ì´ì§€ ë‚´ìš© ê°€ì ¸ì˜¤ê¸°"""
        try:
            response = self.session.get(url, timeout=15)
            response.encoding = encoding

            if response.status_code == 200:
                return BeautifulSoup(response.content, 'html.parser')
            return None
        except Exception:
            return None

    def extract_program_info_from_li(self, li_element):
        """li ìš”ì†Œì—ì„œ í”„ë¡œê·¸ë¨ ì •ë³´ ì¶”ì¶œ"""
        try:
            program_info = {
                'title': '',
                'region': '',
                'location': '',
                'status': '',
                'application_period': '',
                'link': '',
                'program_date': '',
                'description': ''
            }

            link_element = li_element.select_one('a')
            if link_element:
                href = link_element.get('href', '')
                if href:
                    program_info['link'] = urljoin(self.base_url, href)

            recruit_state = li_element.select_one('.recruit_state .ing')
            if not recruit_state or recruit_state.get_text(strip=True) != 'ëª¨ì§‘ì¤‘':
                return None
            program_info['status'] = 'ëª¨ì§‘ì¤‘'

            recruit_tit = li_element.select_one('.recruit_tit')
            if recruit_tit:
                title = recruit_tit.get_text(strip=True)
                program_info['title'] = title

                region_match = re.search(r'\[([^]]+êµ¬)\]', title)
                if region_match:
                    program_info['region'] = region_match.group(1)

            recruit_date = li_element.select_one('.recruit_date')
            if recruit_date:
                date_spans = recruit_date.find_all('span')
                if len(date_spans) >= 2:
                    program_info['application_period'] = date_spans[1].get_text(strip=True)

            part3 = li_element.select_one('.part3')
            if part3:
                location_text = part3.get_text(strip=True)
                if location_text:
                    program_info['location'] = location_text

            return program_info if program_info['title'] and program_info['status'] == 'ëª¨ì§‘ì¤‘' else None

        except Exception:
            return None

    def extract_programs_from_page(self, soup):
        """í˜ì´ì§€ì—ì„œ í”„ë¡œê·¸ë¨ ëª©ë¡ ì¶”ì¶œ"""
        programs = []
        program_list = soup.select('ul li')

        for li_element in program_list:
            try:
                if li_element.select_one('.recruit_state'):
                    program_info = self.extract_program_info_from_li(li_element)
                    if program_info:
                        programs.append(program_info)
            except Exception:
                continue

        return programs

    def has_program_content(self, soup):
        """í˜ì´ì§€ì— í”„ë¡œê·¸ë¨ ì½˜í…ì¸ ê°€ ìˆëŠ”ì§€ í™•ì¸"""
        if not soup:
            return False
        return len(soup.select('.recruit_state')) > 0

    def crawl_all_programs(self):
        """ëª¨ë“  ì²­ë…„ í”„ë¡œê·¸ë¨ í¬ë¡¤ë§"""
        all_programs = []

        for page in range(1, 6):
            if page == 1:
                url = "https://young.busan.go.kr/policySupport/act.nm?menuCd=261"
                soup = self.get_page_content(url)
            else:
                possible_urls = [
                    f"https://young.busan.go.kr/policySupport/act.nm?menuCd=261&pageIndex={page}",
                    f"https://young.busan.go.kr/policySupport/act.nm?menuCd=261&page={page}",
                    f"https://young.busan.go.kr/policySupport/act.nm?menuCd=261&currentPage={page}",
                ]

                soup = None
                for url in possible_urls:
                    soup = self.get_page_content(url)
                    if soup and self.has_program_content(soup):
                        break
                    time.sleep(0.5)

                if not soup or not self.has_program_content(soup):
                    break

            if not soup:
                continue

            page_programs = self.extract_programs_from_page(soup)
            if not page_programs:
                break

            all_programs.extend(page_programs)
            time.sleep(1)  # í˜ì´ì§€ ê°„ ì§€ì—°

        self.programs_data = all_programs
        return all_programs


# === ì§€ì—­ ë§¤í•‘ ìƒìˆ˜ ===
LOCATION_MAPPINGS = {
    'í•´ìš´ëŒ€': 'í•´ìš´ëŒ€êµ¬', 'í•´ìš´ëŒ€ ì²­ë…„ì±„ì›€ê³µê°„': 'í•´ìš´ëŒ€êµ¬', 'í•´ìš´ëŒ€ ì²­ë…„JOBì¹´í˜': 'í•´ìš´ëŒ€êµ¬', 'í•´ìš´ëŒ€ ì²­ë…„ì¡ì¹´í˜': 'í•´ìš´ëŒ€êµ¬',
    'ê³ ê³ ì”½': 'ë‚¨êµ¬', 'ì²­ë…„ì°½ì¡°ë°œì „ì†Œ ê³ ê³ ì”½ Job': 'ë‚¨êµ¬', 'ì²­ë…„ì°½ì¡°ë°œì „ì†Œ  ê³ ê³ ì”½ Job': 'ë‚¨êµ¬',
    'ì²­ë…„ì°½ì¡°ë°œì „ì†Œ ê³ ê³ ì”½': 'ë‚¨êµ¬', 'ë™ë„¤ ì²­ë…„ê³µê°„ ê³µê°„ìˆ²': 'ë‚¨êµ¬', 'ê³µê°„ìˆ²': 'ë‚¨êµ¬', 'ë‚¨êµ¬': 'ë‚¨êµ¬',
    'ê¿ˆí„°': 'ê¸ˆì •êµ¬', 'ì²­ë…„ì°½ì¡°ë°œì „ì†Œ ê¿ˆí„°+': 'ê¸ˆì •êµ¬', 'ì²­ë…„ì°½ì¡°ë°œì „ì†Œ   ê¿ˆí„°+': 'ê¸ˆì •êµ¬',
    'ì²­ë…„ì°½ì¡°ë°œì „ì†Œ ê¿ˆí„°': 'ê¸ˆì •êµ¬', 'ê¸ˆì •': 'ê¸ˆì •êµ¬', 'ê¸ˆì •êµ¬': 'ê¸ˆì •êµ¬',
    'ì²­ë…„ì‘ë‹¹ì†Œ': 'ì¤‘êµ¬', 'ì²­ë…„ë¬¸í™”êµë¥˜ê³µê°„': 'ì¤‘êµ¬', 'ì²­ë…„ë¬¸í™”êµë¥˜ê³µê°„ \'ì²­ë…„ì‘ë‹¹ì†Œ\'': 'ì¤‘êµ¬',
    'ì²­ë…„ë¬¸í™”êµë¥˜ê³µê°„ ì²­ë…„ì‘ë‹¹ì†Œ': 'ì¤‘êµ¬', 'ë¶€ì‚°ì²­ë…„ì„¼í„°': 'ì¤‘êµ¬', 'ì˜¤ë¦„ë¼ìš´ì§€': 'ì¤‘êµ¬',
    'ì¤‘êµ¬ ì²­ë…„ì„¼í„°': 'ì¤‘êµ¬', 'ì¤‘êµ¬': 'ì¤‘êµ¬',
    'ë¶€ì‚°ì§„êµ¬': 'ë¶€ì‚°ì§„êµ¬', 'ì™€ê¸€ì™€ê¸€í”Œë«í¼': 'ë¶€ì‚°ì§„êµ¬', 'ì²­ë…„ FLEX': 'ë¶€ì‚°ì§„êµ¬',
    'ë¶€ì‚°ì§„êµ¬ì²­ë…„í”Œë«í¼': 'ë¶€ì‚°ì§„êµ¬', 'ì²­ë…„ë‘ë“œë¦¼ì„¼í„°': 'ë¶€ì‚°ì§„êµ¬',
    'ì²­ë…„ì°½ì¡°ë°œì „ì†Œ ë””ìì¸ìŠ¤í”„ë§': 'ë¶€ì‚°ì§„êµ¬', 'ë””ìì¸ìŠ¤í”„ë§': 'ë¶€ì‚°ì§„êµ¬',
    'ì²­ë…„ë§ˆìŒê±´ê°•ì„¼í„°': 'ë¶€ì‚°ì§„êµ¬', 'ë¶€ì‚°ì²­ë…„ì¡': 'ë¶€ì‚°ì§„êµ¬',
    'ë™ë˜': 'ë™ë˜êµ¬', 'ë™ë˜êµ¬': 'ë™ë˜êµ¬', 'ë™ë˜êµ¬ ì²­ë…„ì–´ìš¸ë¦¼ì„¼í„°': 'ë™ë˜êµ¬',
    'ì˜ë„': 'ì˜ë„êµ¬', 'ì˜ë„êµ¬': 'ì˜ë„êµ¬', 'ë‹¤:ì´ë£¸': 'ì˜ë„êµ¬', 'ì²­ë…„í¬ë§í”Œë«í¼': 'ì˜ë„êµ¬',
    'ë¶êµ¬': 'ë¶êµ¬', 'ì„œêµ¬': 'ì„œêµ¬', 'ë™êµ¬': 'ë™êµ¬', 'ì‚¬í•˜': 'ì‚¬í•˜êµ¬', 'ì‚¬í•˜êµ¬': 'ì‚¬í•˜êµ¬',
    'ê°•ì„œ': 'ê°•ì„œêµ¬', 'ê°•ì„œêµ¬': 'ê°•ì„œêµ¬', 'ì—°ì œ': 'ì—°ì œêµ¬', 'ì—°ì œêµ¬': 'ì—°ì œêµ¬',
    'ìˆ˜ì˜': 'ìˆ˜ì˜êµ¬', 'ìˆ˜ì˜êµ¬': 'ìˆ˜ì˜êµ¬', 'ì‚¬ìƒ': 'ì‚¬ìƒêµ¬', 'ì‚¬ìƒêµ¬': 'ì‚¬ìƒêµ¬',
    'ê¸°ì¥': 'ê¸°ì¥êµ°', 'ê¸°ì¥êµ°': 'ê¸°ì¥êµ°'
}


# === í—¬í¼ í•¨ìˆ˜ë“¤ ===
def parse_deadline_date(application_period):
    """ì‹ ì²­ê¸°ê°„ì—ì„œ ë§ˆê°ì¼ ì¶”ì¶œ ë° íŒŒì‹±"""
    try:
        if not application_period:
            return None

        date_pattern = r'(\d{4})[.-](\d{1,2})[.-](\d{1,2})'
        dates = re.findall(date_pattern, application_period)

        if len(dates) >= 2:
            year, month, day = dates[1]
            return datetime(int(year), int(month), int(day))
        elif len(dates) == 1:
            year, month, day = dates[0]
            return datetime(int(year), int(month), int(day))

        return None
    except Exception:
        return None


def get_region_from_location(location, spaces_data=None):
    """ì¥ì†Œëª…ìœ¼ë¡œë¶€í„° ì§€ì—­ ì¶”ì¶œ"""
    if not location:
        return ""

    if spaces_data:
        for space in spaces_data:
            space_name = space.get('name', '').strip()

            if location.strip() == space_name:
                return space.get('region', '')

            if (space_name in location or location in space_name) and len(space_name) > 3:
                return space.get('region', '')

    location_clean = location.strip()
    if location_clean in LOCATION_MAPPINGS:
        return LOCATION_MAPPINGS[location_clean]

    sorted_mappings = sorted(LOCATION_MAPPINGS.items(), key=lambda x: len(x[0]), reverse=True)
    for keyword, region in sorted_mappings:
        if keyword in location and len(keyword) > 2:
            return region

    return ""


def get_cache_paths():
    """ìºì‹œ íŒŒì¼ ê²½ë¡œ ë°˜í™˜"""
    basedir = os.path.abspath(os.path.dirname(__file__))
    project_root = os.path.dirname(basedir)
    instance_path = os.path.join(os.environ.get('RENDER_DISK_PATH', project_root), 'instance')
    os.makedirs(instance_path, exist_ok=True)

    return os.path.join(instance_path, 'youth_programs_cache.json')


def get_youth_programs_data():
    """ì²­ë…„ í”„ë¡œê·¸ë¨ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (ìºì‹œ ìš°ì„ )"""
    cache_file = get_cache_paths()
    cache_duration = timedelta(hours=3)

    if os.path.exists(cache_file):
        try:
            with open(cache_file, 'r', encoding='utf-8') as f:
                cached_data = json.load(f)

            cache_time = datetime.fromisoformat(cached_data['cached_at'])
            if datetime.now() - cache_time < cache_duration:
                return cached_data['data']
        except Exception:
            pass

    crawler = BusanYouthProgramCrawler()
    programs = crawler.crawl_all_programs()

    cache_data = {
        'cached_at': datetime.now().isoformat(),
        'data': programs
    }

    try:
        with open(cache_file, 'w', encoding='utf-8') as f:
            json.dump(cache_data, f, ensure_ascii=False, indent=2)
    except Exception:
        pass

    return programs


def normalize_region(region):
    """ì§€ì—­ëª… ì •ê·œí™”"""
    if region.endswith('êµ¬') or region.endswith('êµ°'):
        return region[:-1]
    return region


def match_program_region(program, region, region_normalized, spaces_data):
    """í”„ë¡œê·¸ë¨ê³¼ ì§€ì—­ ë§¤ì¹­ ê²€ì‚¬"""
    program_region = program.get('region', '')
    program_location = program.get('location', '')
    program_title = program.get('title', '')

    if region_normalized in program_title or f"[{region}]" in program_title:
        return True

    if region in program_region or region_normalized in program_region:
        return True

    location_region = get_region_from_location(program_location, spaces_data)
    if location_region and (region in location_region or region_normalized in location_region):
        if not program_region:
            program['region'] = location_region
        return True

    return False


def format_program_list(programs, region, max_count=3):
    """í”„ë¡œê·¸ë¨ ëª©ë¡ í¬ë§·íŒ…"""
    if not programs:
        return (f"ğŸ“Œ {region} ì²­ë…„ê³µê°„ í”„ë¡œê·¸ë¨ ì•ˆë‚´(ë§ˆê° ì„ë°•ìˆœ)\n\n"
                f"í˜„ì¬ {region}ì—ì„œ ëª¨ì§‘ì¤‘ì¸ ì²­ë…„ ê³µê°„ í”„ë¡œê·¸ë¨ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n"
                "ë‹¤ë¥¸ ì§€ì—­ì„ ì„ íƒí•´ë³´ì‹œê±°ë‚˜, ì „ì²´ í”„ë¡œê·¸ë¨ì„ í™•ì¸í•´ë³´ì„¸ìš”!\n\n"
                "ğŸ“Œ ì „ì²´ í”„ë¡œê·¸ë¨ì€ [ì²­ë…„ ê³µê°„ í”„ë¡œê·¸ë¨](https://young.busan.go.kr/policySupport/act.nm?menuCd=261)ì—ì„œ ë” í™•ì¸í•  ìˆ˜ ìˆì–´ìš”.")

    programs.sort(key=lambda x: (
        x['deadline_date'] is None,
        x['deadline_date'] if x['deadline_date'] else datetime.max
    ))

    result = f"ğŸ“Œ {region} ì²­ë…„ê³µê°„ í”„ë¡œê·¸ë¨ ì•ˆë‚´(ë§ˆê° ì„ë°•ìˆœ)\n\n"
    display_count = min(max_count, len(programs))

    for i, program in enumerate(programs[:display_count], 1):
        display_region = program.get('region', '') or region

        program_title = program.get('title', 'í”„ë¡œê·¸ë¨ëª… ì—†ìŒ')
        for region_tag in [f"[{region}]", f"[{display_region}]"]:
            program_title = program_title.replace(region_tag, "").strip()

        result += f"{i}\\.\u00A0{display_region} {program_title}\n"
        result += f"\u00A0\u00A0ğŸ“ ì¥ì†Œ : {program.get('location', 'ì¥ì†Œ ë¯¸ì •')}\n"
        result += f"\u00A0\u00A0ğŸ“… ì‹ ì²­ê¸°ê°„ : {program.get('application_period', 'ì‹ ì²­ê¸°ê°„ ë¯¸ì •')}\n"

        if program.get('link'):
            result += f"\u00A0\u00A0ğŸ”— [ìì„¸íˆ ë³´ê¸°]({program['link']})\n"
        result += "\n"

    if len(programs) > max_count:
        result += f"... ì™¸ {len(programs) - max_count}ê°œ í”„ë¡œê·¸ë¨ ë” ìˆìŒ\n\n"

    result += "ğŸ“Œ ì „ì²´ í”„ë¡œê·¸ë¨ì€ [ì²­ë…„ ê³µê°„ í”„ë¡œê·¸ë¨](https://young.busan.go.kr/policySupport/act.nm?menuCd=261)ì—ì„œ ë” í™•ì¸í•  ìˆ˜ ìˆì–´ìš”."
    return result


# === ë©”ì¸ ê²€ìƒ‰ í•¨ìˆ˜ë“¤ ===
def search_programs_by_region(region):
    """ì§€ì—­ë³„ ì²­ë…„ í”„ë¡œê·¸ë¨ ê²€ìƒ‰"""
    programs = get_youth_programs_data()

    try:
        from services.youth_space_crawler import get_youth_spaces_data
        spaces_data = get_youth_spaces_data()
    except Exception:
        spaces_data = []

    if not programs:
        return f"ğŸ“Œ {region} ì²­ë…„ê³µê°„ í”„ë¡œê·¸ë¨ ì•ˆë‚´(ë§ˆê° ì„ë°•ìˆœ)\n\ní˜„ì¬ í”„ë¡œê·¸ë¨ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\nğŸ“Œ ì „ì²´ í”„ë¡œê·¸ë¨ì€ [ì²­ë…„ ê³µê°„ í”„ë¡œê·¸ë¨](https://young.busan.go.kr/policySupport/act.nm?menuCd=261)ì—ì„œ ë” í™•ì¸í•  ìˆ˜ ìˆì–´ìš”."

    region_normalized = normalize_region(region)
    filtered_programs = []

    for program in programs:
        if match_program_region(program, region, region_normalized, spaces_data):
            deadline = parse_deadline_date(program.get('application_period', ''))
            program['deadline_date'] = deadline
            filtered_programs.append(program)

    return format_program_list(filtered_programs, region)


def search_programs_by_keyword(keyword):
    """í‚¤ì›Œë“œë³„ ì²­ë…„ í”„ë¡œê·¸ë¨ ê²€ìƒ‰"""
    programs = get_youth_programs_data()
    if not programs:
        return "í˜„ì¬ ì²­ë…„ í”„ë¡œê·¸ë¨ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    keyword_lower = keyword.lower()
    filtered_programs = [
        program for program in programs
        if any(keyword_lower in str(program.get(field, '')).lower()
               for field in ['title', 'location', 'region'])
    ]

    if not filtered_programs:
        return f"**{keyword}** ê´€ë ¨ ëª¨ì§‘ì¤‘ì¸ ì²­ë…„ í”„ë¡œê·¸ë¨ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\në‹¤ë¥¸ í‚¤ì›Œë“œë¡œ ê²€ìƒ‰í•´ë³´ì„¸ìš”!"

    result = f"ğŸ” **{keyword}** ê²€ìƒ‰ ê²°ê³¼ ({len(filtered_programs)}ê°œ ëª¨ì§‘ì¤‘)\n\n"

    for program in filtered_programs[:8]:
        result += format_program_info(program) + "\n"

    if len(filtered_programs) > 8:
        result += f"\n... ì™¸ {len(filtered_programs) - 8}ê°œ í”„ë¡œê·¸ë¨ ë” ìˆìŒ"

    return result


def format_program_info(program, deadline_info=""):
    """í”„ë¡œê·¸ë¨ ì •ë³´ í¬ë§·íŒ…"""
    result = f"**{program['title']}**{deadline_info}\n"

    if program.get('status'):
        status_emoji = "ğŸŸ¢" if program['status'] == 'ëª¨ì§‘ì¤‘' else "ğŸ”´"
        result += f"{status_emoji} {program['status']}\n"

    if program.get('application_period'):
        result += f"ğŸ“… ì‹ ì²­ê¸°ê°„: {program['application_period']}\n"

    if program.get('location'):
        result += f"ğŸ“ ì¥ì†Œ: {program['location']}\n"

    if program.get('region'):
        result += f"ğŸ›ï¸ ì§€ì—­: {program['region']}\n"

    if program.get('link'):
        result += f"ğŸ”— [ìì„¸íˆ ë³´ê¸°]({program['link']})\n"

    return result


def get_all_youth_programs():
    """ì „ì²´ ëª¨ì§‘ì¤‘ì¸ ì²­ë…„ í”„ë¡œê·¸ë¨ ëª©ë¡"""
    programs = get_youth_programs_data()
    if not programs:
        return "í˜„ì¬ ì²­ë…„ í”„ë¡œê·¸ë¨ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    result = f"**ë¶€ì‚° ì²­ë…„ í”„ë¡œê·¸ë¨ ëª¨ì§‘ì¤‘** ({len(programs)}ê°œ)\n\n"

    regions = {}
    for program in programs:
        region = program.get('region', 'ê¸°íƒ€')
        if not region or region == 'ê¸°íƒ€':
            title = program.get('title', '')
            region_match = re.search(r'\[([^]]+êµ¬)\]', title)
            region = region_match.group(1) if region_match else 'ì „ì²´/ê¸°íƒ€'

        regions.setdefault(region, []).append(program)

    for region, region_programs in sorted(regions.items()):
        result += f"**{region}** ({len(region_programs)}ê°œ)\n"
        for program in region_programs[:3]:
            result += f"{program['title']}\n"
            if program.get('application_period'):
                result += f"{program['application_period']}\n"

        if len(region_programs) > 3:
            result += f"     ... ì™¸ {len(region_programs) - 3}ê°œ ë”\n"
        result += "\n"

    result += "ğŸ’¡ ì§€ì—­ëª…ì´ë‚˜ í”„ë¡œê·¸ë¨ëª…ìœ¼ë¡œ ìì„¸í•œ ì •ë³´ë¥¼ ê²€ìƒ‰í•´ë³´ì„¸ìš”!"
    return result


def get_programs_by_category():
    """ì¹´í…Œê³ ë¦¬ë³„ í”„ë¡œê·¸ë¨ ë¶„ë¥˜"""
    programs = get_youth_programs_data()
    if not programs:
        return "í˜„ì¬ ì²­ë…„ í”„ë¡œê·¸ë¨ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    categories = {
        'ì·¨ì—…/ì§„ë¡œ': ['ì·¨ì—…', 'job', 'ì»¨ì„¤íŒ…', 'ë©´ì ‘', 'ì´ë ¥ì„œ'],
        'êµìœ¡/ê°•ì˜': ['êµìœ¡', 'ê°•ì˜', 'ê³¼ì •', 'êµì‹¤', 'ìŠ¤ì¿¨'],
        'ì°½ì—…': ['ì°½ì—…', 'ì‚¬ì—…', 'ë¹„ì¦ˆë‹ˆìŠ¤'],
        'ë¬¸í™”/ì˜ˆìˆ ': ['ë¬¸í™”', 'ì˜ˆìˆ ', 'ê³µì—°', 'ì „ì‹œ', 'ìŒì•…', 'ë¯¸ìˆ '],
        'ê¸°íƒ€': []
    }

    categorized_programs = {category: [] for category in categories}

    for program in programs:
        title = program.get('title', '').lower()
        categorized = False

        for category, keywords in categories.items():
            if category != 'ê¸°íƒ€' and any(keyword in title for keyword in keywords):
                categorized_programs[category].append(program)
                categorized = True
                break

        if not categorized:
            categorized_programs['ê¸°íƒ€'].append(program)

    result = "**ì¹´í…Œê³ ë¦¬ë³„ ì²­ë…„ í”„ë¡œê·¸ë¨**\n\n"

    for category, category_programs in categorized_programs.items():
        if category_programs:
            result += f"**{category}** ({len(category_programs)}ê°œ)\n"
            for program in category_programs[:3]:
                result += f"{program['title']}\n"
            if len(category_programs) > 3:
                result += f"     ... ì™¸ {len(category_programs) - 3}ê°œ ë”\n"
            result += "\n"

    return result