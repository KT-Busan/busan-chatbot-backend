import requests
import re
import time
from bs4 import BeautifulSoup
from urllib.parse import urljoin
from datetime import datetime


class YouthProgramScraper:
    def __init__(self):
        self.base_url = "https://www.busanjob.net"
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
        })

    def scrape_youth_programs(self, max_programs=3):
        """ì²­ë…„ í”„ë¡œê·¸ë¨ ëª©ë¡ ìˆ˜ì§‘ (ìµœëŒ€ max_programsê°œ)"""
        try:
            url = "https://www.busanjob.net/03_part/part01_ddr.asp"
            response = self.session.get(url, timeout=10)
            response.encoding = 'euc-kr'
            soup = BeautifulSoup(response.content, 'html.parser')

            programs = []

            # í”„ë¡œê·¸ë¨ ëª©ë¡ì´ ìˆëŠ” í…Œì´ë¸” ì°¾ê¸°
            tables = soup.find_all('table')

            for table in tables:
                rows = table.find_all('tr')

                for i, row in enumerate(rows):
                    if len(programs) >= max_programs:
                        break

                    cells = row.find_all(['td', 'th'])
                    if len(cells) >= 3:
                        # ì²« ë²ˆì§¸ í–‰ì´ í—¤ë”ì¸ì§€ í™•ì¸
                        if i == 0 and any(keyword in cell.get_text() for cell in cells for keyword in
                                          ['ë²ˆí˜¸', 'ì œëª©', 'ë¶„ë¥˜', 'ë“±ë¡ì¼', 'ë§ˆê°ì¼', 'ìƒíƒœ']):
                            continue

                        program_info = self.extract_program_info_from_row(cells, url)
                        if program_info and program_info['title'] and len(program_info['title']) > 2:
                            # ì¤‘ë³µ ì œê±° (ì œëª©ì´ ê°™ì€ í”„ë¡œê·¸ë¨ ì œì™¸)
                            if not any(p['title'] == program_info['title'] for p in programs):
                                programs.append(program_info)

                if len(programs) >= max_programs:
                    break

            # ë“±ë¡ì¼ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ (ìµœì‹  ìˆœ)
            programs_with_dates = []
            programs_without_dates = []

            for program in programs:
                register_date = self.parse_date(program.get('register_date', ''))
                if register_date:
                    program['register_date_obj'] = register_date
                    programs_with_dates.append(program)
                else:
                    programs_without_dates.append(program)

            # ë“±ë¡ì¼ì´ ìµœì‹ ì¸ ê²ƒì„ ìš°ì„ ìœ¼ë¡œ ì •ë ¬
            programs_with_dates.sort(key=lambda x: x['register_date_obj'], reverse=True)

            return programs_with_dates + programs_without_dates

        except Exception as e:
            print(f"Error scraping youth programs: {str(e)}")
            return []

    def extract_program_info_from_row(self, cells, base_url):
        """í…Œì´ë¸” í–‰ì—ì„œ í”„ë¡œê·¸ë¨ ì •ë³´ ì¶”ì¶œ"""
        try:
            program_info = {
                'title': '',
                'category': '',
                'status': '',
                'register_date': '',
                'deadline': '',
                'link': '',
                'details': ''
            }

            # ì…€ ë‚´ìš© ì¶”ì¶œ
            cell_texts = [cell.get_text(strip=True) for cell in cells]

            if len(cell_texts) >= 3:
                for i, text in enumerate(cell_texts):
                    if not text or text.isdigit():
                        continue

                    # ì œëª© ì°¾ê¸° (ê°€ì¥ ê¸´ í…ìŠ¤íŠ¸ ë˜ëŠ” ë§í¬ê°€ ìˆëŠ” í…ìŠ¤íŠ¸)
                    if not program_info['title'] and len(text) > 3:
                        # ë§í¬ê°€ ìˆëŠ” ì…€ì—ì„œ ì œëª© ì¶”ì¶œ
                        link_element = cells[i].find('a')
                        if link_element:
                            program_info['title'] = text
                            href = link_element.get('href')
                            if href:
                                if href.startswith('http'):
                                    program_info['link'] = href
                                else:
                                    program_info['link'] = urljoin(base_url, href)
                        elif len(text) > 5 and not program_info['title']:
                            program_info['title'] = text

                    # ìƒíƒœ ì •ë³´ ì°¾ê¸° (ëª¨ì§‘ì¤‘, ë§ˆê°, ì§„í–‰ì¤‘ ë“±)
                    elif any(status in text for status in ['ëª¨ì§‘ì¤‘', 'ë§ˆê°', 'ì§„í–‰ì¤‘', 'ì¢…ë£Œ', 'ì ‘ìˆ˜ì¤‘']):
                        program_info['status'] = text

                    # ë¶„ë¥˜ ì •ë³´ ì°¾ê¸°
                    elif any(category in text for category in ['êµìœ¡', 'ë¬¸í™”', 'ì·¨ì—…', 'ì°½ì—…', 'ì²´í—˜', 'í”„ë¡œê·¸ë¨']):
                        if not program_info['category']:
                            program_info['category'] = text

                    # ë‚ ì§œ ì •ë³´ ì°¾ê¸°
                    elif self.is_date_format(text):
                        if not program_info['register_date']:
                            program_info['register_date'] = text
                        elif not program_info['deadline']:
                            program_info['deadline'] = text

                # ì„¸ë¶€ ì •ë³´ëŠ” ëª¨ë“  ì…€ì˜ í…ìŠ¤íŠ¸ ì¡°í•©
                program_info['details'] = ' | '.join([t for t in cell_texts if t and not t.isdigit() and len(t) > 1])

                return program_info if program_info['title'] else None

        except Exception as e:
            print(f"Error extracting program info from row: {str(e)}")
            return None

    def is_date_format(self, text):
        """í…ìŠ¤íŠ¸ê°€ ë‚ ì§œ í˜•ì‹ì¸ì§€ í™•ì¸"""
        if not text:
            return False
        return bool(re.search(r'\d{4}[-./]\d{1,2}[-./]\d{1,2}|\d{1,2}[-./]\d{1,2}|\d{4}ë…„|\d{1,2}ì›”', text))

    def parse_date(self, date_str):
        """ë‚ ì§œ ë¬¸ìì—´ì„ ë‚ ì§œ ê°ì²´ë¡œ ë³€í™˜"""
        if not date_str:
            return None

        try:
            # ë‹¤ì–‘í•œ ë‚ ì§œ í˜•ì‹ ì²˜ë¦¬
            date_patterns = [
                r'(\d{4})[-./](\d{1,2})[-./](\d{1,2})',
                r'(\d{4})ë…„\s*(\d{1,2})ì›”\s*(\d{1,2})ì¼?',
                r'(\d{1,2})[-./](\d{1,2})'
            ]

            for pattern in date_patterns:
                match = re.search(pattern, date_str)
                if match:
                    groups = match.groups()
                    if len(groups) == 3:
                        year, month, day = groups
                        if len(year) == 2:
                            year = '20' + year
                        return datetime(int(year), int(month), int(day)).date()
                    elif len(groups) == 2:
                        month, day = groups
                        current_year = datetime.now().year
                        return datetime(current_year, int(month), int(day)).date()

            return None
        except:
            return None


def get_youth_programs():
    """ì²­ë…„ í”„ë¡œê·¸ë¨ ì •ë³´ë¥¼ ê°€ì ¸ì™€ì„œ í¬ë§·íŒ…"""
    try:
        scraper = YouthProgramScraper()
        programs = scraper.scrape_youth_programs(max_programs=3)

        if not programs:
            return "í˜„ì¬ ì²­ë…„ í”„ë¡œê·¸ë¨ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."

        result_text = "ğŸ¯ **ë¶€ì‚° ì²­ë…„ í”„ë¡œê·¸ë¨** ìµœì‹  ì •ë³´ì…ë‹ˆë‹¤!\n\n"

        for i, program in enumerate(programs, 1):
            result_text += f"**{i}. {program['title']}**\n"
            if program.get('category'):
                result_text += f"   - **ë¶„ë¥˜:** {program['category']}\n"
            if program.get('status'):
                result_text += f"   - **ìƒíƒœ:** {program['status']}\n"
            if program.get('register_date'):
                result_text += f"   - **ë“±ë¡ì¼:** {program['register_date']}\n"
            if program.get('deadline'):
                result_text += f"   - **ë§ˆê°ì¼:** {program['deadline']}\n"
            if program.get('link'):
                result_text += f"   - **ìƒì„¸ë³´ê¸°:** [ë§í¬ ë°”ë¡œê°€ê¸°]({program['link']})\n"
            result_text += "\n"

        result_text += "ë” ë§ì€ ì²­ë…„ í”„ë¡œê·¸ë¨ì€ [ë¶€ì‚°ì¡ ì²­ë…„ í”„ë¡œê·¸ë¨ í˜ì´ì§€](https://www.busanjob.net/03_part/part01_ddr.asp)ì—ì„œ í™•ì¸í•˜ì‹¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
        return result_text

    except Exception as e:
        print(f"ì²­ë…„ í”„ë¡œê·¸ë¨ í¬ë¡¤ë§ ì˜¤ë¥˜: {e}")
        return "ì£„ì†¡í•©ë‹ˆë‹¤. í˜„ì¬ ì²­ë…„ í”„ë¡œê·¸ë¨ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” ë° ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì§ì ‘ [ë¶€ì‚°ì¡ ì‚¬ì´íŠ¸](https://www.busanjob.net/03_part/part01_ddr.asp)ë¥¼ ë°©ë¬¸í•´ ì£¼ì„¸ìš”."